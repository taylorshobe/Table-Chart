{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-88e555488802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# Perform the T-Tests and get the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mt_test_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_t_tests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the function to perform T-Tests\n",
    "def perform_t_tests(df, metrics, alpha=0.05):\n",
    "    # Get unique values for 'area' and 'tenured'\n",
    "    areas = df['area'].unique()\n",
    "    tenured_statuses = df['tenured'].unique()\n",
    "    \n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "\n",
    "    for tenured in tenured_statuses:\n",
    "        for area in areas:\n",
    "            for metric in metrics:\n",
    "                # Subset data based on 'area' and 'tenured'\n",
    "                subset = df[(df['tenured'] == tenured) & (df['area'] == area)]\n",
    "                # Separate data into 'HOME' and 'OFFICE' groups\n",
    "                wfh_data = subset[subset['day_type'] == 'HOME'][metric]\n",
    "                office_data = subset[subset['day_type'] == 'OFFICE'][metric]\n",
    "                \n",
    "                if len(wfh_data) > 0 and len(office_data) > 0:\n",
    "                    # Perform T-Test\n",
    "                    t_stat, p_value = ttest_ind(wfh_data, office_data, equal_var=False, nan_policy='omit')\n",
    "                    \n",
    "                    # Calculate means and sample sizes\n",
    "                    wfh_mean = wfh_data.mean()\n",
    "                    office_mean = office_data.mean()\n",
    "                    \n",
    "                    # Append results to the list\n",
    "                    results.append({\n",
    "                        'Tenured': tenured,\n",
    "                        'Area': area,\n",
    "                        'Metric': metric,\n",
    "                        'WFH Mean': wfh_mean,\n",
    "                        'Office Mean': office_mean,\n",
    "                        'T-Statistic': t_stat,\n",
    "                        'P-Value': round(p_value, 5)\n",
    "                    })\n",
    "        \n",
    "        # Add combined area for the current tenured status\n",
    "        for metric in metrics:\n",
    "            combined_subset = df[df['tenured'] == tenured]\n",
    "            wfh_data_combined = combined_subset[combined_subset['day_type'] == 'HOME'][metric]\n",
    "            office_data_combined = combined_subset[combined_subset['day_type'] == 'OFFICE'][metric]\n",
    "            \n",
    "            if len(wfh_data_combined) > 0 and len(office_data_combined) > 0:\n",
    "                # Perform T-Test\n",
    "                t_stat_combined, p_value_combined = ttest_ind(wfh_data_combined, office_data_combined, equal_var=False, nan_policy='omit')\n",
    "                \n",
    "                # Calculate means and sample sizes\n",
    "                wfh_mean_combined = wfh_data_combined.mean()\n",
    "                office_mean_combined = office_data_combined.mean()\n",
    "                \n",
    "                # Append combined area results to the list\n",
    "                results.append({\n",
    "                    'Tenured': tenured,\n",
    "                    'Area': 'All Areas Combined',\n",
    "                    'Metric': metric,\n",
    "                    'WFH Mean': wfh_mean_combined,\n",
    "                    'Office Mean': office_mean_combined,\n",
    "                    'T-Statistic': t_stat_combined,\n",
    "                    'P-Value': round(p_value_combined, 5)\n",
    "                })\n",
    "    \n",
    "    # Convert results list to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Assuming 'result_df' is your DataFrame loaded with your data\n",
    "metrics = ['avg_interaction_count', 'aht', 'avg_productivity']\n",
    "\n",
    "# Set the alpha level (e.g., 0.05 for a 95% confidence level)\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform the T-Tests and get the results\n",
    "t_test_results = perform_t_tests(result_df, metrics)\n",
    "\n",
    "\n",
    "print(t_test_results.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the data into a list of dictionaries\n",
    "data = [\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.755},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Consults\", \"WFH Proportion\": 0.153},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.552},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Chat\", \"Sample\": 4, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.129},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.912},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Consults\", \"WFH Proportion\": 0.206},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.472},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Client Banking Services\", \"Sample\": 46, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.148},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.836},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Consults\", \"WFH Proportion\": 0.178},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.468},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Core Service\", \"Sample\": 594, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.188},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.888},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Consults\", \"WFH Proportion\": 0.104},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"OSAT\", \"WFH Proportion\": 1.000},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Tier 2 Support\", \"Sample\": 5, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.241},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Adherence\", \"WFH Proportion\": 0.822},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Consults\", \"WFH Proportion\": 0.266},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"OSAT\", \"WFH Proportion\": 0.571},\n",
    "    {\"Tenured\": \"No\", \"Area Name\": \"Trader Service\", \"Sample\": 6, \"Metric\": \"Transfers\", \"WFH Proportion\": 0.273},\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding some hypothetical Office Proportion data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "df[\"Office Proportion\"] = np.random.rand(len(df))\n",
    "\n",
    "# Set the alpha level (e.g., 0.05 for a 95% confidence level)\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform Z-tests for each row\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    count = np.array([row[\"WFH Proportion\"] * row[\"Sample\"], row[\"Office Proportion\"] * row[\"Sample\"]])\n",
    "    nobs = np.array([row[\"Sample\"], row[\"Sample\"]])\n",
    "    \n",
    "    z_score, p_value = proportions_ztest(count, nobs)\n",
    "    \n",
    "    results.append({\n",
    "        \"Tenured\": row[\"Tenured\"],\n",
    "        \"Area Name\": row[\"Area Name\"],\n",
    "        \"Sample\": row[\"Sample\"],\n",
    "        \"Metric\": row[\"Metric\"],\n",
    "        \"WFH Proportion\": row[\"WFH Proportion\"],\n",
    "        \"Office Proportion\": row[\"Office Proportion\"],\n",
    "        \"Z-Statistic\": z_score,\n",
    "        \"P-Value\": p_value,\n",
    "        \"Significant\": p_value < alpha  # Check if the p-value is less than the alpha level\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Add combined area for each tenured status\n",
    "combined_results = []\n",
    "\n",
    "for tenured in df['Tenured'].unique():\n",
    "    for metric in df['Metric'].unique():\n",
    "        combined_subset = df[(df['Tenured'] == tenured) & (df['Metric'] == metric)]\n",
    "        combined_sample = combined_subset['Sample'].sum()\n",
    "        combined_wfh_proportion = (combined_subset['WFH Proportion'] * combined_subset['Sample']).sum() / combined_sample\n",
    "        combined_office_proportion = (combined_subset['Office Proportion'] * combined_subset['Sample']).sum() / combined_sample\n",
    "        \n",
    "        count_combined = np.array([combined_wfh_proportion * combined_sample, combined_office_proportion * combined_sample])\n",
    "        nobs_combined = np.array([combined_sample, combined_sample])\n",
    "        \n",
    "        z_score_combined, p_value_combined = proportions_ztest(count_combined, nobs_combined)\n",
    "        \n",
    "        combined_results.append({\n",
    "            \"Tenured\": tenured,\n",
    "            \"Area Name\": \"COMBINED\",\n",
    "            \"Sample\": combined_sample,\n",
    "            \"Metric\": metric,\n",
    "            \"WFH Proportion\": combined_wfh_proportion,\n",
    "            \"Office Proportion\": combined_office_proportion,\n",
    "            \"Z-Statistic\": z_score_combined,\n",
    "            \"P-Value\": p_value_combined,\n",
    "            \"Significant\": p_value_combined < alpha  # Check if the p-value is less than the alpha level\n",
    "        })\n",
    "\n",
    "# Convert combined results to a DataFrame and append to the original results\n",
    "df_combined_results = pd.DataFrame(combined_results)\n",
    "df_final_results = pd.concat([df_results, df_combined_results], ignore_index=True)\n",
    "\n",
    "# Reorder the columns\n",
    "df_final_results = df_final_results[[\"Tenured\", \"Area Name\", \"Sample\", \"Metric\", \"WFH Proportion\", \"Office Proportion\", \"Z-Statistic\", \"P-Value\", \"Significant\"]]\n",
    "\n",
    "print(df_final_results.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
